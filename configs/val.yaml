# Multi-Task Learning (ir, cls, seg)
# For training
# python src/main.py fit --config s2_ir.yaml
# For validation
# python src/main.py validate --config s2_ir.yaml --trainer.logger null
seed_everything: 42
trainer: # ref: https://lightning.ai/docs/pytorch/stable/cli/lightning_cli.html#lightning-cli
  # Hardware settings
  accelerator: gpu
  strategy: auto
  devices: [0, 1, 2, 3, 4, 5, 6, 7]
  precision: 32 # 32 (TWCC), bf16-mixed (4090)
  
  # For debugging
  # fast_dev_run: 8
  # limit_train_batches: 0.4
  # limit_val_batches: 20

  # For iteration-based training
  max_steps: 250000 
  val_check_interval: 6000 
  check_val_every_n_epoch: null
  log_every_n_steps: 25
  accumulate_grad_batches: 6
  num_sanity_val_steps: 2
  strategy: ddp_find_unused_parameters_true

  logger: 
    class_path: TensorBoardLogger
    init_args:
      save_dir: logs/unirestore/test
      name: MTL
      # version: tmp # comment out to use auto generated version name

  callbacks: 
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 5
        monitor: val_monitor
        mode: max
        filename: "epoch={epoch}-val={val_monitor:.4f}"
        auto_insert_metric_name: false
        save_on_train_epoch_end: false

model:
  class_path: core.engine_unifie.LitUniFIEIR 
  init_args:
    save_image: False
    eval_mode: ALL # FR, NR, ALL
    need_crop: True
    model_kwargs:
      frenc: # CFRM
        train: false
        ckpt_path: $path_to_stage1_ckpt$
        type: CFRM
      cnet:
        train: false
        ckpt_path: $path_to_stage1_ckpt$
        type: scedit
        num_inference_steps: 1     # can choose 1~4 diffusion steps
      tedit: # TFA
        ckpt_path:  $path_to_stage2_ckpt$
        type: TFA
        prompt_len: 1
        task: ["ir", "cls", "seg"]
        train: false
    optimizer_kwargs: 
      opt: adamw
      base_lr: 1e-4
      base_bsz: 64
      weight_decay: 1e-2
    lr_scheduler_kwargs:
      sched: onecycle

data:
  class_path: data.DatasetEngine
  init_args:
    task: mtl
    train: 
      type: all
      resolution: 512
      batch_size: 1  # must be 1 for mtl
    val:
      type: val
      val_list: []
      batch_size: 1  # must be 1 for mtl
    crp_mode: common
    num_workers: 4
    prefetch_factor: 4

